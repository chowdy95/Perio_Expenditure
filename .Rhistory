# Define base variable names
base_vars <- c(
"Mean_total_billions", "SD_total_billions",
"Mean_perio_billions", "SD_perio_billions",
"Mean_replace_billions", "SD_replace_billions"
)
prediction_selection <- prediction_combined %>%
# First, pick the selected model based on your logic
mutate(
selected_model = case_when(
Mean_total_billions_high < 0.6 * Dent_exp_usd ~ "high",
Mean_total_billions_mid < 0.6 * Dent_exp_usd ~ "mid",
TRUE ~ "low"
)
) %>%
mutate(
Mean_total_billions = NA_real_,
Mean_perio_billions = NA_real_,
Mean_replace_billions = NA_real_,
SD_total_billions = NA_real_,
SD_perio_billions = NA_real_,
SD_replace_billions = NA_real_
) %>%
# Then, for each base variable, create the "selected_" version
mutate(across(
all_of(base_vars),
~ case_when(
selected_model == "high" ~ get(paste0(cur_column(), "_high")),
selected_model == "mid" ~ get(paste0(cur_column(), "_mid")),
selected_model == "low" ~ get(paste0(cur_column(), "_low"))
),
.names = "selected_{.col}"
)) %>%
mutate(across(
all_of(base_vars),
~ case_when(
selected_model == "high" ~ get(paste0(cur_column(), "_high")),
selected_model == "mid" ~ get(paste0(cur_column(), "_WHO_target")),
selected_model == "low" ~ get(paste0(cur_column(), "_WHO_target"))
),
.names = "WHO_selected_{.col}"
)) %>%
select(-(Mean_total_billions:SD_replace_billions))
global_row <- prediction_selection %>%
summarise(
Country = "Global",
across(contains("selected_Mean"), ~ sum(.x, na.rm = TRUE), .names = "{.col}"),
across(contains("selected_SD"), ~ sqrt(sum(.x^2, na.rm = TRUE)), .names = "{.col}")
)
prediction_selection <- prediction_selection %>%
bind_rows(global_row) %>%
select(
Country,
selected_model:WHO_selected_SD_replace_billions,
everything()
) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>% # read GBD hierarchy
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")) # matching with ISO code for country names
prediction_selection_joined <- hier %>%
full_join(prediction_selection, by = "iso3c") %>%
filter(!is.na(Country.y)) %>%
mutate(Country = coalesce(Country.y, Country.x)) %>%
select(-Country.x, -Country.y)
regions <- prediction_selection_joined %>%
filter(!is.na(Superregion)) %>%
group_by(Region) %>%
summarise(
Superregion = first(Superregion),
across(contains("selected_Mean"), ~ sum(.x, na.rm = TRUE), .names = "{.col}"),
across(contains("selected_SD"), ~ sqrt(sum(.x^2, na.rm = TRUE)), .names = "{.col}")
)
superregions <- prediction_selection_joined %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion) %>%
summarise(
across(contains("selected_Mean"), ~ sum(.x, na.rm = TRUE), .names = "{.col}"),
across(contains("selected_SD"), ~ sqrt(sum(.x^2, na.rm = TRUE)), .names = "{.col}")
)
prediction_selection_hier <- bind_rows(prediction_selection_joined, regions, superregions) %>%
mutate(
Level = case_when(
Country == "Global" ~ 0,
is.na(Country) & is.na(Region) ~ 1,
is.na(Country) & !is.na(Region) ~ 2,
TRUE ~ 3
),
# Create Location Header with indentation
LocationHeader = case_when(
Level == 0 ~ paste(Country), # no indent
Level == 1 ~ paste0(Superregion), # no indent
Level == 2 ~ paste0("  ", Region), # 2 spaces
Level == 3 ~ paste0("    ", Country) # 4 spaces
)
) %>%
select(LocationHeader, everything()) %>%
arrange(desc(LocationHeader == "Global"), Superregion, !is.na(Region), Region, !is.na(Country))
View(prediction_selection)
# ------------------------------------------------------------------------
# 0. Load Packages
# ------------------------------------------------------------------------
library(tidyverse)
library(countrycode)
# ------------------------------------------------------------------------
# 1. Load Data
# ------------------------------------------------------------------------
prediction_high <- read_csv("outputs/country_combined_high.csv") %>%
rename_with(~ paste0(.x, "_high"), -Country)
prediction_mid <- read_csv("outputs/country_combined_mid.csv") %>%
rename_with(~ paste0(.x, "_mid"), -Country)
prediction_low <- read_csv("outputs/country_combined_low.csv") %>%
rename_with(~ paste0(.x, "_low"), -Country)
other_predictors <- read_csv("data/2021_prevalence_pop_dentexp_GDP.csv")
# Combine all data
prediction_combined <- reduce(
list(prediction_high, prediction_mid, prediction_low, other_predictors),
left_join,
by = "Country"
) %>%
mutate(Country = ifelse(Country == "Micronesia",
"Micronesia (Federated States of)", Country))
# Load GBD hierarchy
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
# ------------------------------------------------------------------------
# 2. Function to select model and aggregate at region/superregion/global
# ------------------------------------------------------------------------
run_sensitivity_region <- function(cap_pct) {
sel <- prediction_combined %>%
mutate(
# Select total dental expenditure based on cap
selected_Mean_total_billions = case_when(
Mean_total_billions_high < cap_pct * Dent_exp_usd ~ Mean_total_billions_high,
Mean_total_billions_mid  < cap_pct * Dent_exp_usd ~ Mean_total_billions_mid,
TRUE ~ Mean_total_billions_low
),
iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")
) %>%
full_join(hier, by = "iso3c")
# Aggregate at Region
regions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion, Region) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Region", Location = Region)
# Aggregate at Superregion
superregions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Superregion", Location = Superregion)
# Global
global <- tibble(
Location = "Global",
Level = "Global",
selected_Mean_total_billions = sum(sel$selected_Mean_total_billions, na.rm = TRUE)
)
# Combine
bind_rows(global, regions, superregions)
}
# ------------------------------------------------------------------------
# 3. Run for 60%, 50%, 40%
# ------------------------------------------------------------------------
results_60 <- run_sensitivity_region(0.75) %>% rename(total60 = selected_Mean_total_billions)
results_50 <- run_sensitivity_region(0.5) %>% rename(total50 = selected_Mean_total_billions)
results_40 <- run_sensitivity_region(0.4) %>% rename(total40 = selected_Mean_total_billions)
# ------------------------------------------------------------------------
# 4. Combine results and calculate deltas
# ------------------------------------------------------------------------
sensitivity_df <- results_60 %>%
left_join(results_50 %>% select(Location, total50), by = "Location") %>%
left_join(results_40 %>% select(Location, total40), by = "Location") %>%
mutate(
baseline = total60,
delta_50 = total50 - total60,
delta_50_pct = 100 * delta_50 / total60,
delta_40 = total40 - total60,
delta_40_pct = 100 * delta_40 / total60,
max_abs_pct_change = pmax(abs(delta_50_pct), abs(delta_40_pct))
) %>%
select(Location, Level, baseline, total40, total50, total60,
delta_50, delta_50_pct, delta_40, delta_40_pct, max_abs_pct_change) %>%
arrange(Level, Location)
View(sensitivity_df)
# ------------------------------------------------------------------------
# 0. Load Packages
# ------------------------------------------------------------------------
library(tidyverse)
library(countrycode)
# ------------------------------------------------------------------------
# 1. Load Data
# ------------------------------------------------------------------------
prediction_high <- read_csv("outputs/country_combined_high.csv") %>%
rename_with(~ paste0(.x, "_high"), -Country)
prediction_mid <- read_csv("outputs/country_combined_mid.csv") %>%
rename_with(~ paste0(.x, "_mid"), -Country)
prediction_low <- read_csv("outputs/country_combined_low.csv") %>%
rename_with(~ paste0(.x, "_low"), -Country)
other_predictors <- read_csv("data/2021_prevalence_pop_dentexp_GDP.csv")
prediction_combined <- reduce(
list(prediction_high, prediction_mid, prediction_low, other_predictors),
left_join, by = "Country"
) %>%
mutate(Country = ifelse(Country == "Micronesia",
"Micronesia (Federated States of)", Country))
# Load GBD hierarchy
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
# ------------------------------------------------------------------------
# 2. Function to select model and aggregate at region/superregion/global
# ------------------------------------------------------------------------
run_sensitivity_region <- function(cap_pct) {
sel <- prediction_combined %>%
mutate(
selected_Mean_total_billions = case_when(
Mean_total_billions_high < cap_pct * Dent_exp_usd ~ Mean_total_billions_high,
Mean_total_billions_mid  < cap_pct * Dent_exp_usd ~ Mean_total_billions_mid,
TRUE ~ Mean_total_billions_low
),
iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")
) %>%
full_join(hier, by = "iso3c")
# Aggregate at Region
regions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion, Region) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE),
.groups = "drop") %>%
mutate(Level = "Region", Location = Region)
# Aggregate at Superregion
superregions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE),
.groups = "drop") %>%
mutate(Level = "Superregion", Location = Superregion)
# Global
global <- tibble(
Location = "Global",
Level = "Global",
selected_Mean_total_billions = sum(sel$selected_Mean_total_billions, na.rm = TRUE)
)
bind_rows(global, regions, superregions)
}
# ------------------------------------------------------------------------
# 3. Run for Baseline (75%), Reduced 60% and 50%
# ------------------------------------------------------------------------
results_75 <- run_sensitivity_region(0.75) %>% rename(Baseline_75pct = selected_Mean_total_billions)
results_60 <- run_sensitivity_region(0.60) %>% rename(Reduced_60pct = selected_Mean_total_billions)
results_50 <- run_sensitivity_region(0.50) %>% rename(Reduced_50pct = selected_Mean_total_billions)
# ------------------------------------------------------------------------
# 4. Combine results and calculate deltas
# ------------------------------------------------------------------------
sensitivity_df <- results_75 %>%
left_join(results_60 %>% select(Location, Reduced_60pct), by = "Location") %>%
left_join(results_50 %>% select(Location, Reduced_50pct), by = "Location") %>%
mutate(
delta_60 = Reduced_60pct - Baseline_75pct,
delta_60_pct = 100 * delta_60 / Baseline_75pct,
delta_50 = Reduced_50pct - Baseline_75pct,
delta_50_pct = 100 * delta_50 / Baseline_75pct,
max_abs_pct_change = pmax(abs(delta_60_pct), abs(delta_50_pct))
) %>%
select(Location, Level, Baseline_75pct, Reduced_60pct, Reduced_50pct,
delta_60, delta_60_pct, delta_50, delta_50_pct, max_abs_pct_change) %>%
arrange(Level, Location)
# ------------------------------------------------------------------------
# 5. Save output
# ------------------------------------------------------------------------
write_csv(sensitivity_df, "outputs/sensitivity_analysis_expenditure_cap.csv")
# ------------------------------------------------------------------------
# 0. Load Packages
# ------------------------------------------------------------------------
library(tidyverse)
library(countrycode)
# ------------------------------------------------------------------------
# 1. Load Data
# ------------------------------------------------------------------------
prediction_high <- read_csv("outputs/country_combined_high.csv") %>%
rename_with(~ paste0(.x, "_high"), -Country)
prediction_mid <- read_csv("outputs/country_combined_mid.csv") %>%
rename_with(~ paste0(.x, "_mid"), -Country)
prediction_low <- read_csv("outputs/country_combined_low.csv") %>%
rename_with(~ paste0(.x, "_low"), -Country)
other_predictors <- read_csv("data/2021_prevalence_pop_dentexp_GDP.csv")
prediction_combined <- reduce(
list(prediction_high, prediction_mid, prediction_low, other_predictors),
left_join, by = "Country"
) %>%
mutate(Country = ifelse(Country == "Micronesia",
"Micronesia (Federated States of)", Country))
# Load GBD hierarchy
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
# ------------------------------------------------------------------------
# 2. Function to compute totals per cap and aggregate properly
# ------------------------------------------------------------------------
run_sensitivity <- function(cap_pct) {
prediction_combined %>%
mutate(
selected_total = case_when(
Mean_total_billions_high < cap_pct * Dent_exp_usd ~ Mean_total_billions_high,
Mean_total_billions_mid  < cap_pct * Dent_exp_usd ~ Mean_total_billions_mid,
TRUE ~ Mean_total_billions_low
),
iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")
) %>%
left_join(hier %>% select(iso3c, Superregion, Region), by = "iso3c") %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion, Region) %>%
summarise(total = sum(selected_total, na.rm = TRUE), .groups = "drop") %>%
ungroup() %>%
# Aggregate at Superregion
bind_rows(
. %>% group_by(Superregion) %>% summarise(total = sum(total), .groups = "drop") %>% mutate(Region = NA)
) %>%
# Add Global row
bind_rows(tibble(Superregion = NA, Region = NA, total = sum(.$total, na.rm = TRUE))) %>%
# Add Level and Location for publication-ready table
mutate(
Level = case_when(
is.na(Superregion) & is.na(Region) ~ "Global",
!is.na(Superregion) & is.na(Region) ~ "Superregion",
TRUE ~ "Region"
),
Location = case_when(
Level == "Global" ~ "Global",
Level == "Superregion" ~ Superregion,
Level == "Region" ~ paste0("    ", Region)
)
) %>%
arrange(Level, Superregion, Region)
}
# ------------------------------------------------------------------------
# 3. Run baseline (75%) and reductions (60%, 50%)
# ------------------------------------------------------------------------
results_75 <- run_sensitivity(0.75) %>% rename(Baseline_75pct = total)
'# ------------------------------------------------------------------------
# 0. Load Packages
# ------------------------------------------------------------------------
library(tidyverse)
library(countrycode)
# ------------------------------------------------------------------------
# 1. Load Data
# ------------------------------------------------------------------------
prediction_high <- read_csv("outputs/country_combined_high.csv") %>%
rename_with(~ paste0(.x, "_high"), -Country)
prediction_mid <- read_csv("outputs/country_combined_mid.csv") %>%
rename_with(~ paste0(.x, "_mid"), -Country)
prediction_low <- read_csv("outputs/country_combined_low.csv") %>%
rename_with(~ paste0(.x, "_low"), -Country)
other_predictors <- read_csv("data/2021_prevalence_pop_dentexp_GDP.csv")
prediction_combined <- reduce(
list(prediction_high, prediction_mid, prediction_low, other_predictors),
left_join, by = "Country"
) %>%
mutate(Country = ifelse(Country == "Micronesia",
"Micronesia (Federated States of)", Country))
# Load GBD hierarchy
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
# ------------------------------------------------------------------------
# 2. Function to compute totals per cap
# ------------------------------------------------------------------------
run_sensitivity <- function(cap_pct) {
# Select model based on cap
sel <- prediction_combined %>%
mutate(
selected_total = case_when(
Mean_total_billions_high < cap_pct * Dent_exp_usd ~ Mean_total_billions_high,
Mean_total_billions_mid  < cap_pct * Dent_exp_usd ~ Mean_total_billions_mid,
TRUE ~ Mean_total_billions_low
),
iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")
) %>%
left_join(hier %>% select(iso3c, Superregion, Region), by = "iso3c") %>%
filter(!is.na(Superregion))
# Aggregate at Region
regions <- sel %>%
group_by(Superregion, Region) %>%
summarise(total = sum(selected_total, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Region", Location = Region)
# Aggregate at Superregion
superregions <- regions %>%
group_by(Superregion) %>%
summarise(total = sum(total, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Superregion", Location = Superregion)
# Global total
global <- tibble(
Level = "Global",
Location = "Global",
total = sum(superregions$total, na.rm = TRUE)
)
bind_rows(global, superregions, regions)
}
# ------------------------------------------------------------------------
# 3. Run baseline (75%) and reductions (60%, 50%)
# ------------------------------------------------------------------------
results_75 <- run_sensitivity(0.75) %>% rename(Baseline_75pct = total)
results_60 <- run_sensitivity(0.60) %>% rename(Reduced_60pct = total)
results_50 <- run_sensitivity(0.50) %>% rename(Reduced_50pct = total)
# ------------------------------------------------------------------------
# 4. Merge and calculate deltas
# ------------------------------------------------------------------------
sensitivity_df <- results_75 %>%
left_join(results_60 %>% select(Location, Reduced_60pct), by = "Location") %>%
left_join(results_50 %>% select(Location, Reduced_50pct), by = "Location") %>%
mutate(
delta_60 = Reduced_60pct - Baseline_75pct,
delta_60_pct = 100 * delta_60 / Baseline_75pct,
delta_50 = Reduced_50pct - Baseline_75pct,
delta_50_pct = 100 * delta_50 / Baseline_75pct,
max_abs_pct_change = pmax(abs(delta_60_pct), abs(delta_50_pct))
) %>%
select(Location, Level, Baseline_75pct, Reduced_60pct, Reduced_50pct,
delta_60, delta_60_pct, delta_50, delta_50_pct, max_abs_pct_change) %>%
arrange(match(Level, c("Global", "Superregion", "Region")), Superregion, Region)
# ------------------------------------------------------------------------
# 5. Save output
# ------------------------------------------------------------------------
write_csv(sensitivity_df, "outputs/sensitivity_analysis_total_expenditure_pubready.csv")
# ------------------------------------------------------------------------
# 0. Load Packages
# ------------------------------------------------------------------------
library(tidyverse)
library(countrycode)
# ------------------------------------------------------------------------
# 1. Load Data
# ------------------------------------------------------------------------
prediction_high <- read_csv("outputs/country_combined_high.csv") %>%
rename_with(~ paste0(.x, "_high"), -Country)
prediction_mid <- read_csv("outputs/country_combined_mid.csv") %>%
rename_with(~ paste0(.x, "_mid"), -Country)
prediction_low <- read_csv("outputs/country_combined_low.csv") %>%
rename_with(~ paste0(.x, "_low"), -Country)
other_predictors <- read_csv("data/2021_prevalence_pop_dentexp_GDP.csv")
# Combine all data
prediction_combined <- reduce(
list(prediction_high, prediction_mid, prediction_low, other_predictors),
left_join,
by = "Country"
) %>%
mutate(Country = ifelse(Country == "Micronesia",
"Micronesia (Federated States of)", Country))
# Load GBD hierarchy
hier <- read_csv("data/GBD_location_hierarchy_wide.csv", locale = locale(encoding = "Latin1")) %>%
mutate(iso3c = countrycode(Country, origin = "country.name", destination = "iso3c"))
# ------------------------------------------------------------------------
# 2. Function to select model and aggregate at region/superregion/global
# ------------------------------------------------------------------------
run_sensitivity_region <- function(cap_pct) {
sel <- prediction_combined %>%
mutate(
# Select total dental expenditure based on cap
selected_Mean_total_billions = case_when(
Mean_total_billions_high < cap_pct * Dent_exp_usd ~ Mean_total_billions_high,
Mean_total_billions_mid  < cap_pct * Dent_exp_usd ~ Mean_total_billions_mid,
TRUE ~ Mean_total_billions_low
),
iso3c = countrycode(Country, origin = "country.name", destination = "iso3c")
) %>%
full_join(hier, by = "iso3c")
# Aggregate at Region
regions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion, Region) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Region", Location = Region)
# Aggregate at Superregion
superregions <- sel %>%
filter(!is.na(Superregion)) %>%
group_by(Superregion) %>%
summarise(selected_Mean_total_billions = sum(selected_Mean_total_billions, na.rm = TRUE), .groups = "drop") %>%
mutate(Level = "Superregion", Location = Superregion)
# Global
global <- tibble(
Location = "Global",
Level = "Global",
selected_Mean_total_billions = sum(sel$selected_Mean_total_billions, na.rm = TRUE)
)
# Combine
bind_rows(global, regions, superregions)
}
# ------------------------------------------------------------------------
# 3. Run for 60%, 50%, 40%
# ------------------------------------------------------------------------
results_75 <- run_sensitivity_region(0.75) %>% rename(total75 = selected_Mean_total_billions)
results_60 <- run_sensitivity_region(0.6) %>% rename(total60 = selected_Mean_total_billions)
results_50 <- run_sensitivity_region(0.5) %>% rename(total50 = selected_Mean_total_billions)
# ------------------------------------------------------------------------
# 4. Combine results and calculate deltas
# ------------------------------------------------------------------------
sensitivity_df <- results_75 %>%
left_join(results_60 %>% select(Location, total60), by = "Location") %>%
left_join(results_50 %>% select(Location, total50), by = "Location") %>%
mutate(
baseline = total75,
delta_60 = total60 - total75,
delta_60_pct = 100 * delta_60 / total75,
delta_50 = total50 - total75,
delta_50_pct = 100 * delta_50 / total75,
) %>%
select(Location, Level, baseline,
delta_60, delta_60_pct, delta_50, delta_50_pct) %>%
arrange(Level, Location)
# ------------------------------------------------------------------------
# 5. Save output
# ------------------------------------------------------------------------
write_csv(sensitivity_df, "outputs/sensitivity_analysis_perio_cap_expenditure.csv")
View(sensitivity_df)
View(sensitivity_df)
View(sensitivity_df)
